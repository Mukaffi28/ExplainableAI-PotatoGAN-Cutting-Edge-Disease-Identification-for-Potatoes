{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201 \n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, log_loss, jaccard_score\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from shutil import copyfile \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset Describtion**\n",
    "* train - 70%\n",
    "* test - 20%\n",
    "* validation - 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to our train, validation, and test datasets\n",
    "train_data_dir =  'C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato with XAI data\\\\Train'\n",
    "test_data_dir = 'C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato with XAI data\\\\Test'\n",
    "validation_data_dir = 'C:\\\\Users\\\\Mukaffi\\\\Desktop\\\\Potato with XAI data\\\\Validation'\n",
    "\n",
    "\n",
    "# Image dimensions\n",
    "IMG_WIDTH, IMG_HEIGHT = 299, 299\n",
    "input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)  # RGB images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data generators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators for RGB images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "# Define data generators for RGB images with augmentation\n",
    "train_datagen_augmented = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,  # Rotation angle range\n",
    "    width_shift_range=0.2,  # Horizontal shift range\n",
    "    height_shift_range=0.2,  # Vertical shift range\n",
    "    shear_range=0.2,  # Shear intensity\n",
    "    zoom_range=0.2,  # Random zoom range\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    vertical_flip=False,  # Do not flip images vertically\n",
    "    fill_mode='nearest'  # Fill mode for newly created pixels\n",
    ")\n",
    "\n",
    "# Generate augmented data for training\n",
    "train_generator = train_datagen_augmented.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=10,\n",
    "    class_mode='categorical',\n",
    "  \n",
    ")\n",
    "\n",
    "\n",
    "# Define data generators for RGB images with augmentation\n",
    "test_datagen_augmented = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,  # Rotation angle range\n",
    "    width_shift_range=0.2,  # Horizontal shift range\n",
    "    height_shift_range=0.2,  # Vertical shift range\n",
    "    shear_range=0.2,  # Shear intensity\n",
    "    zoom_range=0.2,  # Random zoom range\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    vertical_flip=False,  # Do not flip images vertically\n",
    "    fill_mode='nearest'  # Fill mode for newly created pixels\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "   )\n",
    "\n",
    "# Define data generators for RGB images with augmentation\n",
    "validation_datagen_augmented = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,  # Rotation angle range\n",
    "    width_shift_range=0.2,  # Horizontal shift range\n",
    "    height_shift_range=0.2,  # Vertical shift range\n",
    "    shear_range=0.2,  # Shear intensity\n",
    "    zoom_range=0.2,  # Random zoom range\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    vertical_flip=False,  # Do not flip images vertically\n",
    "    fill_mode='nearest'  # Fill mode for newly created pixels\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "   \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **{'Black Scruf': 0, 'Common Scab': 1}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = train_generator.class_indices\n",
    "print(class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Number of images for each class in the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images for each class in the training dataset\n",
    "classes = os.listdir(train_data_dir)\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(train_data_dir, class_name)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    print(f\"Class: {class_name}, Number of images: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Check the shape of the images in Train Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels from the train_generator\n",
    "batch = train_generator.next()\n",
    "\n",
    "# Iterate through the batch to check image shapes\n",
    "for i in range(len(batch[0])):\n",
    "    img = batch[0][i]  # Image data\n",
    "    label = batch[1][i]  # Image label\n",
    "    \n",
    "    # Get image shape and channels\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    # Display image shape and channels\n",
    "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Number of images for each class in the testing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images for each class in the testing dataset\n",
    "classes = os.listdir(test_data_dir)\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(test_data_dir, class_name)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    print(f\"Class: {class_name}, Number of images: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Check the shape of the images in Test Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels from the test_generator\n",
    "batch = test_generator.next()\n",
    "\n",
    "# Iterate through the batch to check image shapes\n",
    "for i in range(len(batch[0])):\n",
    "    img = batch[0][i]  # Image data\n",
    "    label = batch[1][i]  # Image label\n",
    "    \n",
    "    # Get image shape and channels\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    # Display image shape and channels\n",
    "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Number of images for each class in the validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images for each class in the testing dataset\n",
    "classes = os.listdir(validation_data_dir)\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(validation_data_dir, class_name)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    print(f\"Class: {class_name}, Number of images: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Check the shape of the images in Validation Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images and labels from the validation_generator\n",
    "batch = validation_generator.next()\n",
    "\n",
    "# Iterate through the batch to check image shapes\n",
    "for i in range(len(batch[0])):\n",
    "    img = batch[0][i]  # Image data\n",
    "    label = batch[1][i]  # Image label\n",
    "    \n",
    "    # Get image shape and channels\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    # Display image shape and channels\n",
    "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Check for GPU availability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT available\")\n",
    "\n",
    "# Set TensorFlow to use the GPU device\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "    print(\"GPU device configured\")\n",
    "else:\n",
    "    print(\"No GPU device found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cost-Sensitive Learning involves adjusting the loss function or misclassification costs to account for the imbalanced distribution of classes.**\n",
    "\n",
    "## **Weighted Loss Function:**\n",
    "### Modify the loss function to give more weight to the minority class (Fracture) during training. This adjustment helps the model to focus more on correctly classifying the minority class instances.\n",
    "\n",
    "## **Class Weights:**\n",
    "### Assign different weights to each class in the loss calculation. Weight the loss associated with the Fracture class higher than the Non-Fracture class to reflect the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "model_dir = 'D:\\\\Data\\\\Checkpoints_densenet169'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "checkpoint_path = model_dir + '/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,  # Save only the best model\n",
    "                                                 monitor=\"val_accuracy\",   # Monitor validation loss\n",
    "                                                 mode=\"max\",           # Save the model when validation loss is minimized\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DenseNet for Feature Extractor** \n",
    "## **1.** DenseNet169\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(summary=True):\n",
    "    # apply transfer learning\n",
    "    new_input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    base_model = DenseNet169(weights='imagenet', include_top=False, input_tensor=new_input) ##MobileNetV3Small(weights='imagenet', include_top=False, input_tensor=new_input)\n",
    "    # add new classifier layers\n",
    "    flat1 = Flatten()(base_model.layers[-1].output)\n",
    "    output = Dense(5, activation='softmax')(flat1)  # Change to 1 for binary classification\n",
    "    # define new model\n",
    "    model = Model(inputs=base_model.inputs, outputs=output)\n",
    "    # Modify loss function to 'weighted_binary_crossentropy'\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    if summary:\n",
    "        print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training starts here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    batch_size=10,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[cp_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Save model history in a CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training history\n",
    "initial_epoch = 0  # or the actual initial epoch of the first training session\n",
    "saved_history = {\n",
    "    'loss': history.history['loss'],\n",
    "    'accuracy': history.history['accuracy'],\n",
    "    'val_loss': history.history['val_loss'],\n",
    "    'val_accuracy': history.history['val_accuracy'],\n",
    "    # Add other metrics as needed\n",
    "}\n",
    "np.save(\"D:\\Data\\saved_history.npy\", saved_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(history.history).to_csv(\"D:\\\\Data\\\\densenet_densenetEpoch5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Again Train the loaded model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latest checkpoint file\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest_checkpoint)\n",
    "\n",
    "if latest_checkpoint is not None:\n",
    "    # Create a new model instance\n",
    "    loaded_model = create_model(summary=True)\n",
    "\n",
    "    # Load the previously saved weights and silence the warnings\n",
    "    status = loaded_model.load_weights(latest_checkpoint)\n",
    "    status.expect_partial()  # Ignore unrestored variables\n",
    "else:\n",
    "    print(\"No checkpoint file found in the specified directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous history\n",
    "previous_history = np.load(\"D:\\Data\\saved_history.npy\", allow_pickle=True).item()\n",
    "initial_epoch = len(previous_history['loss'])\n",
    "print(initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(optimizer=Adam(learning_rate=1e-3), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "# Train the model\n",
    "#initial_epoch = 20\n",
    "new_history  = loaded_model.fit(\n",
    "    train_generator,\n",
    "    epochs=2,\n",
    "    initial_epoch=initial_epoch,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[cp_callback]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Again save the history after using latest weights in a CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update and save the training history\n",
    "previous_history['loss'].extend(new_history.history['loss'])\n",
    "previous_history['accuracy'].extend(new_history.history['accuracy'])\n",
    "previous_history['val_loss'].extend(new_history.history['val_loss'])\n",
    "previous_history['val_accuracy'].extend(new_history.history['val_accuracy'])\n",
    "# Repeat for other metrics as needed\n",
    "\n",
    "np.save(\"D:\\Data\\saved_history.npy\", previous_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(previous_history).to_csv(\"D:\\\\Data\\\\Checkpoints_dense121Epoch.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Accuracy and loss graph of training and validation**\n",
    "## Here, No. of epochs and (xticks & yticks) will be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "import numpy as np\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Loss\n",
    "train_loss, = plt.plot(previous_history['loss'], label='Train Loss', color='blue')\n",
    "val_loss, = plt.plot(previous_history['val_loss'], label='Validation Loss', color='orange')\n",
    "train_accuracy, = plt.plot(previous_history['accuracy'], label='Train Accuracy',  color='green')\n",
    "val_accuracy, = plt.plot(previous_history['val_accuracy'], label='Validation Accuracy', color='red')\n",
    "# Add a title with specified font properties\n",
    "plt.title('Model Performance during Training', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12},pad=10)\n",
    "# Set x-axis label with specified font properties\n",
    "plt.xlabel('No. of Epochs', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "\n",
    "# Set x-axis ticks font properties\n",
    "#plt.xticks(np.linspace(0, len(history.history['loss']), num=6), fontname='Serif', weight='bold')\n",
    "\n",
    "plt.xticks(np.linspace(0, 100, num=11), fontname='Serif', weight='bold')\n",
    "\n",
    "\n",
    "# Set y-axis ticks font properties\n",
    "plt.yticks(np.linspace(0, 4, num=5), fontname='Serif', weight='bold')\n",
    "\n",
    "# Set the x-axis and y-axis limits\n",
    "#plt.xlim(0, len(history.history['loss']))\n",
    "\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 4)\n",
    "\n",
    "# Define custom legend lines with desired line properties\n",
    "legend_lines = [\n",
    "    Line2D([0], [0], color='blue', lw=3),          # Train Loss\n",
    "    Line2D([0], [0], color='orange', lw=3),       # Validation Loss\n",
    "    Line2D([0], [0], color='green', lw=3),        # Train Accuracy\n",
    "    Line2D([0], [0], color='red', lw=3)           # Validation Accuracy\n",
    "]\n",
    "\n",
    "# Place legend outside the graph by adjusting bbox_to_anchor and specifying it to be outside the axes\n",
    "plt.legend(legend_lines, ['Train Loss', 'Validation Loss', 'Train Accuracy', 'Validation Accuracy'],\n",
    "           loc='lower center', bbox_to_anchor=(0.5, 1.1), ncol=5,\n",
    "           prop={'family': 'Serif', 'weight': 'bold', 'size': 8}, frameon=False,\n",
    "           handler_map={Line2D: HandlerLine2D(numpoints=5)})\n",
    "\n",
    "# Adjust padding between x-axis label and x-axis ticks\n",
    "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "# Adjust layout to prevent cropping\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\Data\\\\Lung_densenet169_accuracy_graph.pdf')  # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing starts here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latest checkpoint file\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest_checkpoint is not None:\n",
    "    # Create a new model instance\n",
    "    loaded_model = create_model(summary=True)\n",
    "\n",
    "    # Load the previously saved weights and silence the warnings\n",
    "    status = loaded_model.load_weights(latest_checkpoint)\n",
    "    status.expect_partial()  # Ignore unrestored variables\n",
    "else:\n",
    "    print(\"No checkpoint file found in the specified directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = loaded_model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels for the test set\n",
    "predictions = loaded_model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)  # Get the index of the highest probability class\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Display some of the predicted and true classes\n",
    "print(\"Predicted Classes:\", predicted_classes[-10:])  # Display first 10 predicted classes\n",
    "print(\"True Classes:\", true_classes[-10:])  # Display first 10 true classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_classes\n",
    "logloss = log_loss(true_classes, predicted_classes)\n",
    "print(f\"Log Loss: {logloss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation Metircs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy_score(true_classes, predicted_classes)}\")\n",
    "print(f\"Precision: {precision_score(true_classes, predicted_classes,average='weighted')}\")\n",
    "print(f\"Recall: {recall_score(true_classes, predicted_classes,average='weighted')}\")\n",
    "print(f\"F1 Score: {f1_score(true_classes, predicted_classes,average='weighted')}\")\n",
    "#print(f\"Log Loss: {log_loss(true_classes, predicted_classes)}\")\n",
    "print(f\"Jaccard Score: {jaccard_score(true_classes, predicted_classes,average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, jaccard_score\n",
    "\n",
    "# Weighted metrics\n",
    "#weighted_accuracy = accuracy_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "#weighted_log_loss = log_loss(true_classes, predicted_classes, labels=list(set(true_classes)), eps=1e-15)\n",
    "weighted_jaccard = jaccard_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "\n",
    "print(f\"Weighted Precision: {weighted_precision}\")\n",
    "print(f\"Weighted Recall: {weighted_recall}\")\n",
    "print(f\"Weighted F1 Score: {weighted_f1}\")\n",
    "#print(f\"Weighted Log Loss: {weighted_log_loss}\")\n",
    "print(f\"Weighted Jaccard Score: {weighted_jaccard}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Weighted precision, recall, and F1 score\n",
    "# weighted_precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "# weighted_recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "# weighted_f1 = f1_score(true_classes, predicted_classes, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Weighted Precision: {weighted_precision}\")\n",
    "# print(f\"Weighted Recall: {weighted_recall}\")\n",
    "# print(f\"Weighted F1 Score: {weighted_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "# Define the custom palette\n",
    "custom_palette = sns.color_palette(palette='GnBu')# Modify the number based on number of classes in the dataset\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "font2 = {'family': 'Serif', 'weight': 'bold', 'size': 10}\n",
    "\n",
    "# Create heatmap with annotations and colormap\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette,vmin = 0,vmax = 950,\n",
    "                      xticklabels=['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc'], \n",
    "                      yticklabels=['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc'],\n",
    "                      annot_kws={\"family\": \"Serif\", 'color':'black','weight': 'bold', 'size': 13})\n",
    "\n",
    "# Set x and y labels with the custom font dictionary\n",
    "heatmap.set_xlabel('Predicted Labels', fontdict=font2)\n",
    "heatmap.set_ylabel('Target Labels', fontdict=font2)\n",
    "#heatmap.set_title('Fundus Image Classification\\nAccuracy: {:.2f}%'.format(accuracy_percentage),fontdict=font, pad=12)\n",
    "\n",
    "# Set font properties for tick labels on both axes\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=12)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=12)\n",
    "\n",
    "# Create a color bar to indicate the scale\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label('Count', fontdict=font)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "# Adjust padding between x-axis label and x-axis ticks\n",
    "plt.gca().xaxis.labelpad = 10  # Change the value as needed to adjust the space\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "# Adjust layout to prevent cropping\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:\\\\Data\\\\Lung_densenet169_cm.pdf')  # Save as pdf format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No. 1 : Explainable AI (GradCAM)**\n",
    "### **Step 1:** Prepare the Model (We've done it already)\n",
    "### **Step 2:** Load and Preprocess an Image (We'll need an image to visualize the Grad-CAM heatmap)\n",
    "### **Step 3:** Get the Class Activation Map (CAM) (We'll create a function to generate the Grad-CAM heatmap using the model we've built)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function for displaying GradCAM images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save and display GradCAM\n",
    "def save_and_display_gradcam(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('GradCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\\\Data\\\\Lung_densenet169_gradcam.pdf')  # Save as pdf formatD:\\\\Data\\\\EfficientNetB4_gradcam_plusplus.pdf\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GradCAM function**\n",
    "### **Gradient Calculation:** Using these activations, GradCAM computes the gradients of the predicted class's score with respect to the feature maps. These gradients indicate the importance of each feature map in determining the final class prediction.\n",
    "\n",
    "### **Global Average Pooling (GAP):** GradCAM takes the gradients and performs Global Average Pooling (GAP) across the spatial dimensions of each feature map. This step generates a weight for each feature map, reflecting its relevance to the predicted class.\n",
    "\n",
    "### **Weighted Combination:** GradCAM computes a weighted combination of the feature maps based on their importance weights obtained from GAP. This combination highlights the regions in the feature maps that strongly influence the predicted class.\n",
    "\n",
    "### **Heatmap Generation:** The weighted combination produces a heatmap by overlaying these selected regions back onto the input image. The heatmap visually demonstrates which parts of the image are pivotal in the model's decision-making for the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of Grad-Cam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # make a prediction and visualize grad-cam\n",
    "def make_prediction_and_visualize_():\n",
    "    img_path = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Test\\\\colon_n\\\\colonn5.jpeg'\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299)) #IMG_WIDTH, IMG_HEIGHT\n",
    "    rescaled_img = img/255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "\n",
    "    last_conv_layer_name = 'conv5_block16_concat'\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = make_gradcam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_gradcam(img_path, heatmap)\n",
    "\n",
    "\n",
    "make_prediction_and_visualize_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No. 2 : Explainable AI (GradCAM++)**\n",
    "### **Step 1:** Prepare the Model (We've done it already)\n",
    "### **Step 2:** Load and Preprocess an Image (We'll need an image to visualize the Grad-CAM++ heatmap)\n",
    "### **Step 3:** Get the Class Activation Map (CAM) (We'll create a function to generate the Grad-CAM++ heatmap using the model we've built)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save and display ScoreCAM\n",
    "def save_and_display_gradcam_plusplus(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the GradCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('GradCAM++', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\\\Data\\\\Lung_densenet169__gradcam_plusplus.pdf')  # Save as pdf format\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GradCAM++ function**\n",
    "### **Gradient Computation:** Derive gradients between predicted class and conv layer's output, indicating feature map importance.\n",
    "### **Positive and Negative Gradients:** Split gradients into positive (activating) and negative (inhibiting) parts, signifying influential and counteractive regions.\n",
    "### **Weighting and Aggregation:** Calculate separate importance weights from positive and negative gradients, combining them to determine feature map significance.\n",
    "### **Weighted Sum and Heatmap:** Blend positive and negative weights to generate a weighted sum, utilized for heatmap creation, pinpointing significant regions contributing to the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate GradCAM++ heatmap\n",
    "def make_gradcam_plusplus_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_output = preds[:, pred_index]\n",
    "        conv_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Get gradients\n",
    "    grads = tape.gradient(class_output, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads[0], axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Calculate guided gradients\n",
    "    guided_grads = tf.cast(last_conv_layer_output > 0, 'float32') * grads[0]\n",
    "\n",
    "    # Calculate importance weights\n",
    "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "    # Generate heatmap\n",
    "    heatmap = tf.reduce_sum(tf.multiply(weights, last_conv_layer_output), axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)  # Normalize\n",
    "\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of Grad-Cam++**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a prediction and visualize GradCAM++\n",
    "def make_prediction_and_visualize_gradcam_plusplus():\n",
    "    img_path = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Test\\\\colon_n\\\\colonn5.jpeg'\n",
    "\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
    "    rescaled_img = img / 255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "    last_conv_layer_name = 'conv5_block16_concat'\n",
    "\n",
    "    # Generate GradCAM++ heatmap\n",
    "    heatmap = make_gradcam_plusplus_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_gradcam_plusplus(img_path, heatmap)\n",
    "\n",
    "make_prediction_and_visualize_gradcam_plusplus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **No. 3 : Explainable AI (ScoreCAM)**\n",
    "### **Step 1:** Prepare the Model (We've done it already)\n",
    "### **Step 2:** Load and Preprocess an Image (We'll need an image to visualize the Score-CAM heatmap)\n",
    "### **Step 3:** Get the Class Activation Map (CAM) (We'll create a function to generate the Score-CAM heatmap using the model we've built)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save and display ScoreCAM\n",
    "def save_and_display_scorecam(img_path, heatmap, alpha=0.7):\n",
    "    # Load the original image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299))  # Resize image to match model input size\n",
    "\n",
    "    # Resize heatmap to match the image dimensions\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_PLASMA)\n",
    "\n",
    "    # Apply heatmap on the original image\n",
    "    superimposed_img = cv2.addWeighted(heatmap, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # Display the ScoreCAM visualization using Matplotlib\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('ScoreCAM', fontdict={'family': 'Serif', 'weight': 'bold', 'size': 12})\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    # Save the figure\n",
    "    plt.savefig('D:\\\\Data\\\\Lung_densenet169__scorecam.pdf')  # Save as pdf format\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ScoreCAM function**\n",
    "### **Gradient Computation:** Score-CAM calculates the gradients of the predicted class score with respect to the output feature maps, just like Grad-CAM. These gradients provide information about the importance of each feature map in the predicted class's activation.\n",
    "### **Guided Gradients:** Instead of considering positive and negative gradients separately, Score-CAM utilizes guided gradients to focus only on positive gradients, i.e., gradients that have a positive influence on the predicted class. This step enhances the saliency of the significant regions.\n",
    "### **Global Average Pooling (GAP):** Score-CAM performs Global Average Pooling (GAP) across the spatial dimensions of the guided gradients to generate importance weights for each feature map, indicating their relevance to the predicted class.\n",
    "### **Score-weighted Activation Map:** The technique computes a score-weighted activation map by multiplying the weights obtained from GAP with the feature maps and summing across channels. This highlights the regions in the feature maps that contribute the most to the predicted class, emphasizing the most discriminative areas in the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def make_scorecam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    model.layers[-1].activation = None\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_output = preds[:, pred_index]\n",
    "        conv_output = last_conv_layer_output[0]\n",
    "\n",
    "    # Get the gradients of the predicted class with respect to the output feature map\n",
    "    grads = tape.gradient(class_output, last_conv_layer_output)\n",
    "    guided_grads = tf.cast(grads[0] > 0, 'float32') * grads[0]\n",
    "\n",
    "    # GAP (Global Average Pooling) along the spatial dimensions\n",
    "    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
    "\n",
    "    # Calculate the score-weighted activation map\n",
    "    cam = tf.reduce_sum(tf.multiply(weights, conv_output), axis=-1)\n",
    "    cam = tf.maximum(cam, 0)  # ReLU to ensure non-negativity\n",
    "    cam /= tf.reduce_max(cam)  # Normalize\n",
    "\n",
    "    return cam.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization of ScoreCam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction and visualize ScoreCAM\n",
    "def make_prediction_and_visualize_scorecam():\n",
    "    img_path = 'D:\\\\Our Future works\\\\lung_colon_image_\\\\Test\\\\colon_n\\\\colonn5.jpeg'\n",
    "\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (299, 299)) #IMG_WIDTH, IMG_HEIGHT\n",
    "    rescaled_img = img/255.0\n",
    "    batch_pred = np.expand_dims(rescaled_img, 0)\n",
    "\n",
    "    last_conv_layer_name = 'conv5_block16_concat'\n",
    "\n",
    "    # Generate class activation heatmap\n",
    "    heatmap = make_scorecam_heatmap(batch_pred, loaded_model, last_conv_layer_name)\n",
    "\n",
    "    save_and_display_scorecam(img_path, heatmap)\n",
    "\n",
    "make_prediction_and_visualize_scorecam()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4061437,
     "sourceId": 7056056,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
