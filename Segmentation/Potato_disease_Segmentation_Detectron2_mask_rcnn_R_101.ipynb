{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pyyaml==5.1\n",
    "import sys, os, distutils.core\n",
    "\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register dataset to detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_resume_training = True\n",
    "\n",
    "# Path to your pretrained model weights \n",
    "PRETRAINED_PATH = Path(\"/kaggle/input/output/output (1)/model_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# detectron2\n",
    "from detectron2.utils.memory import retry_if_cuda_oom\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader, DatasetMapper\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm  # progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import cv2\n",
    "import copy\n",
    "from typing import Optional\n",
    "import seaborn as sns\n",
    "\n",
    "!pip install -q pycocotools\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import random\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "sns.set_theme(style='darkgrid', palette='deep', font='sans-serif', font_scale=1)\n",
    "\n",
    "from IPython.display import FileLink\n",
    "# torch\n",
    "import torch\n",
    "import gc\n",
    "import warnings\n",
    "# Ignore \"future\" warnings and Data-Frame-Slicing warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path(\"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_imshow(im):\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(), plt.imshow(im), plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "def get_balloon_dicts(img_dir):\n",
    "    json_file = os.path.join(img_dir, \"via_export.json\")\n",
    "    with open(json_file) as f:\n",
    "        imgs_anns = json.load(f)\n",
    "\n",
    "    category_mapping = {\n",
    "        'Black_Scruf': 0,\n",
    "        'Common_Scab': 1,\n",
    "    }\n",
    "\n",
    "    dataset_dicts = []\n",
    "    for idx, v in enumerate(imgs_anns.values()):\n",
    "        record = {}\n",
    "        #print(idx)\n",
    "        filename = os.path.join(img_dir, v[\"filename\"])\n",
    "        height, width = cv2.imread(filename).shape[:2]\n",
    "\n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "\n",
    "        annos = v[\"regions\"]\n",
    "        #print(filename)\n",
    "        objs = []\n",
    "        for anno in annos:\n",
    "            shape_attributes = anno[\"shape_attributes\"]\n",
    "            region_attributes = anno[\"region_attributes\"]\n",
    "            #print(filename)\n",
    "            px = shape_attributes[\"all_points_x\"]\n",
    "            py = shape_attributes[\"all_points_y\"]\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "            #print(region_attributes)\n",
    "            category_name = region_attributes[\"categories\"]\n",
    "            #print(category_name)\n",
    "            category_id = category_mapping.get(category_name, 0)\n",
    "\n",
    "            obj = {\n",
    "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"segmentation\": [poly],\n",
    "                \"category_id\": category_id,\n",
    "            }\n",
    "            objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"train\"]:\n",
    "    DatasetCatalog.register(\"Potato_\" + d, lambda d=d: get_balloon_dicts(\"/kaggle/input/potato-seg/pot/pot/\" + d))\n",
    "    MetadataCatalog.get(\"Potato_\" + d).set(thing_classes=[\"Common_Scab\",\"Black_Scruf\"])\n",
    "\n",
    "balloon_metadata = MetadataCatalog.get(\"Potato_train\")\n",
    "\n",
    "print(balloon_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balloon_metadata = MetadataCatalog.get(\"Potato_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(balloon_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DatasetCatalog.get(\"Potato_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_dicts = get_balloon_dicts(\"/kaggle/input/potato-seg/pot/pot/train\")\n",
    "for d in dataset_dicts[:1]:\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.MODEL.DEVICE = \"cuda\"\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"Potato_valid\")\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "#cfg.MODEL.WEIGHTS = str(PRETRAINED_PATH)\n",
    "    \n",
    "#mask_rcnn_X_101_32x8d_FPN_3x.yaml \n",
    "#mask_rcnn_R_50_FPN_1x.yaml mask_rcnn_R_101_FPN_3x.yaml\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.BASE_LR = 0.001  \n",
    "cfg.SOLVER.MAX_ITER = 2000   \n",
    "cfg.SOLVER.STEPS = []        \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # Number of class\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Load metrics\n",
    "    metrics_df = pd.read_json(\n",
    "        OUTPUT_DIR/\"metrics.json\", orient=\"records\", lines=True\n",
    "    )\n",
    "    mdf = metrics_df.sort_values(\"iteration\")\n",
    "    #.tail(3)\n",
    "    print(mdf.tail(3).T)\n",
    "\n",
    "    # Plot loss\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    mdf1 = mdf[~mdf[\"total_loss\"].isna()]\n",
    "    ax.plot(mdf1[\"iteration\"], mdf1[\"total_loss\"], c=\"C0\", label=\"train\")\n",
    "\n",
    "    if \"validation_loss\" in mdf.columns:\n",
    "        mdf2 = mdf[~mdf[\"validation_loss\"].isna()]\n",
    "        ax.plot(mdf2[\"iteration\"], mdf2[\"validation_loss\"],\n",
    "                c=\"C1\", label=\"validation\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Loss curve\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    mdf1 = mdf[~mdf[\"mask_rcnn/accuracy\"].isna()]\n",
    "    ax.plot(mdf1[\"iteration\"], mdf1[\"mask_rcnn/accuracy\"],\n",
    "            c=\"C0\", label=\"train\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(\"Accuracy curve\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Bounding Box regressor loss\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    mdf1 = mdf[~mdf[\"loss_box_reg\"].isna()]\n",
    "    ax.plot(mdf1[\"iteration\"], mdf1[\"loss_box_reg\"], c=\"C0\", label=\"train\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(\"loss_box_reg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"Potato_valid\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"Potato_valid\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "fig, ax = plt.subplots(4, 2, figsize=(10, 10))\n",
    "indices = [ax[0][0], ax[1][0], ax[0][1], ax[1][1],\n",
    "           ax[2][0], ax[3][0], ax[2][1], ax[3][1]]\n",
    "i=0\n",
    "dataset_dicts = get_balloon_dicts(\"/kaggle/input/potato-seg/pot/pot/train/\")\n",
    "for d in dataset_dicts[50:58]:\n",
    "    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=balloon_metadata, \n",
    "                   \n",
    "                   instance_mode=ColorMode.IMAGE_BW,\n",
    "                   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "                    # You can adjust this value to set the font size\n",
    "    )\n",
    "    visualizer = v.draw_instance_predictions(\n",
    "        outputs[\"instances\"].to(\"cpu\")\n",
    "    )\n",
    "    display_img = visualizer.get_image()[:, :, ::-1]\n",
    "    indices[i].grid(False)\n",
    "    indices[i].imshow(display_img)\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "fig, ax = plt.subplots(25, 2, figsize=(50, 50))\n",
    "indices = [ax[i // 2, i % 2] for i in range(50)]  # Flatten the 2D array\n",
    "i = 0\n",
    "dataset_dicts = get_balloon_dicts(\"/kaggle/input/potato-seg/pot/pot/train\")\n",
    "\n",
    "for d in dataset_dicts[:50]:  # Loop through the first 50 images\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=balloon_metadata,\n",
    "                   instance_mode=ColorMode.IMAGE_BW,\n",
    "    )\n",
    "    \n",
    "    visualizer = v.draw_instance_predictions(\n",
    "        outputs[\"instances\"].to(\"cpu\")\n",
    "    )\n",
    "    \n",
    "    display_img = visualizer.get_image()[:, :, ::-1]\n",
    "    indices[i].grid(False)\n",
    "    indices[i].imshow(display_img)\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_data_list = get_balloon_dicts(\"/kaggle/input/potato-seg/pot/pot/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.structures import BoxMode\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Assume custom_data_list is a list of dictionaries with 'file_name', 'annotations', etc.\n",
    "dice_scores = []\n",
    "\n",
    "for data in custom_data_list:\n",
    "    # Load the image\n",
    "    file_path = data[\"file_name\"]\n",
    "    image = cv2.imread(file_path)\n",
    "\n",
    "    # Use the predictor to get predictions\n",
    "    outputs = predictor(image)\n",
    "\n",
    "    # Extract predicted bounding boxes\n",
    "    pred_boxes = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
    "\n",
    "    # Extract ground truth bounding boxes\n",
    "    gt_box = data[\"annotations\"][0][\"bbox\"]  # Adjust this based on your annotation structure\n",
    "    gt_box_detectron2 = BoxMode.convert(gt_box, BoxMode.XYXY_ABS, BoxMode.XYXY_ABS)\n",
    "    # Check if there are predictions\n",
    "    if pred_boxes.size == 0:\n",
    "        # No predictions for this image, handle accordingly\n",
    "        continue\n",
    "    # Calculate TP, FP, and FN\n",
    "    x_min = max(gt_box_detectron2[0], pred_boxes[:, 0].min())\n",
    "    y_min = max(gt_box_detectron2[1], pred_boxes[:, 1].min())\n",
    "    x_max = min(gt_box_detectron2[2], pred_boxes[:, 2].max())\n",
    "    y_max = min(gt_box_detectron2[3], pred_boxes[:, 3].max())\n",
    "\n",
    "    intersection_area = max(0, x_max - x_min) * max(0, y_max - y_min)\n",
    "    gt_box_area = (gt_box_detectron2[2] - gt_box_detectron2[0]) * (gt_box_detectron2[3] - gt_box_detectron2[1])\n",
    "    pred_box_area = np.sum((pred_boxes[:, 2] - pred_boxes[:, 0]) * (pred_boxes[:, 3] - pred_boxes[:, 1]))\n",
    "\n",
    "    TP = intersection_area\n",
    "    FP = pred_box_area - TP\n",
    "    FN = gt_box_area - TP\n",
    "\n",
    "    # Calculate Dice score\n",
    "    dice_score = (2 * TP) / (2 * TP + FP + FN)\n",
    "\n",
    "    # Append Dice score to the list\n",
    "    dice_scores.append(dice_score)\n",
    "\n",
    "# Calculate mean Dice score\n",
    "mean_dice_score = np.mean(dice_scores)\n",
    "print(\"Mean Dice Score:\", mean_dice_score)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3583826,
     "sourceId": 7383299,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3964812,
     "sourceId": 7383543,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
